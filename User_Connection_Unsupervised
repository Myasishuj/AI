import pandas as pd
import numpy as np
from datetime import datetime
import unicodedata
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.neighbors import NearestNeighbors
from math import radians, sin, cos, sqrt, atan2


# --- Helpers ---
def normalize(s: str) -> str:
    """Normalizes string by removing accents, lowercasing, and stripping whitespace."""
    return (
        unicodedata.normalize("NFKD", s)
        .encode("ascii", "ignore")
        .decode("ascii")
        .lower()
        .strip()
    )


def haversine_distance(lat1, lon1, lat2, lon2):
    """
    Calculate the distance between two points on Earth using the Haversine formula.
    Parameters are in degrees, returns distance in kilometers.
    """
    R = 6371  # Radius of Earth in kilometers

    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])

    dlon = lon2 - lon1
    dlat = lat2 - lat1

    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))

    distance = R * c
    return distance


def calculate_simple_midpoint(lat1, lon1, lat2, lon2):
    """
    Calculates a simple geographical midpoint (average of lat/lon) between two points.
    For more accuracy over long distances, a spherical midpoint formula would be needed.
    """
    mid_lat = (lat1 + lat2) / 2
    mid_lon = (lon1 + lon2) / 2
    return mid_lat, mid_lon


def get_location_name_from_coords(lat, lon):
    """
    Illustrative placeholder for reverse geocoding to get a human-readable location name (city/town).
    In a real application, this would involve an API call (e.g., Google Maps Geocoding API, Nominatim).
    This version provides more specific city names for common regions based on simplified ranges.
    """
    # Example of a more specific, hardcoded lookup for demonstration purposes
    # In reality, you'd use a robust reverse geocoding library or API.
    # Coordinates are approximate for illustration.
    if 48.15 < lat < 48.16 and 17.86 < lon < 17.87:
        return "Šaľa, Slovakia"
    elif 44.71 < lat < 44.72 and 25.31 < lon < 25.32:
        return "Găești, Romania"
    elif 44.48 < lat < 44.49 and 11.21 < lon < 11.22:
        return "Zola Predosa, Italy"
    elif 48.6 < lat < 48.7 and 22.2 < lon < 22.3:
        return "Uzhhorod, Ukraine"  # Near the border
    elif 48.0 < lat < 49.0 and 17.0 < lon < 18.0:  # Broader Bratislava area
        return "Bratislava Area, Slovakia"
    else:
        return f"Near ({lat:.2f}, {lon:.2f})"  # Fallback for unknown regions


# --- 1. Load and preprocess data ---
INPUT_CSV = "SocialMediaUsersDataset_with_coordinates.csv"
try:
    df = pd.read_csv(INPUT_CSV)
    print(f"Loaded '{INPUT_CSV}'. Shape: {df.shape}")
except FileNotFoundError:
    print(f"Error: File '{INPUT_CSV}' not found.")
    exit()

# Remove duplicates
initial_rows = len(df)
df.drop_duplicates(inplace=True)
print(f"Removed {initial_rows - len(df)} duplicates. New shape: {df.shape}")

# Optional sampling (disable for full evaluation)
USE_SAMPLE = False
SAMPLE_FRACTION = 0.1
if USE_SAMPLE:
    df = df.sample(frac=SAMPLE_FRACTION, random_state=42).reset_index(drop=True)
    print(f"Sampled to {df.shape}")

# Age from DOB
df['DOB'] = pd.to_datetime(df['DOB'], errors='coerce')
current_date = pd.Timestamp(datetime.now())
calculated_age_series = (current_date - df['DOB']).dt.days / 365.25
df['age'] = calculated_age_series
if df['age'].isnull().any():
    mean_age = calculated_age_series.mean()
    fill_value = mean_age if not pd.isna(mean_age) else 0
    df['age'] = df['age'].fillna(fill_value)

print(f"Age calculated. Range: {df['age'].min():.2f}–{df['age'].max():.2f}")

# Coordinates - fill NaNs with mean
df['latitude'] = df['latitude'].fillna(df['latitude'].mean() if not df['latitude'].isnull().all() else 0.0)
df['longitude'] = df['longitude'].fillna(df['longitude'].mean() if not df['longitude'].isnull().all() else 0.0)
coords = df[['latitude', 'longitude']].values

# Interests normalization
df['Interests'] = df['Interests'].astype(str).apply(lambda x: normalize(x.replace("'", " ")))
interests = df['Interests']

# --- 2. Feature extraction ---
tfidf = TfidfVectorizer(max_features=100, ngram_range=(1, 2))
X_text = tfidf.fit_transform(interests)

numeric_scaler = StandardScaler()
X_num = numeric_scaler.fit_transform(np.column_stack([df['age'].values.reshape(-1, 1), coords]))

# Combine features. You could add weights here if desired, e.g., X_text * 1.0, X_num * 2.0
X_combined = np.hstack([X_text.toarray(), X_num])
pca = PCA(n_components=50)
X_reduced = pca.fit_transform(X_combined)

# --- 3. NearestNeighbors model ---
n_neighbors = 3  # Number of neighbors to find (excluding self)
nn_model = NearestNeighbors(n_neighbors=n_neighbors + 1, metric='cosine')  # +1 to include self
nn_model.fit(X_reduced)
distances, indices = nn_model.kneighbors(X_reduced)


# --- 4. Friend recommendation function ---
def get_friend_recommendations(user_id, num_recommendations=10, initial_threshold=0.85, min_threshold=0.75, step=0.05,
                               max_geo_distance_km=750):
    """
    Generates friend recommendations for a given user, applying similarity and geographical filters.
    Also calculates the midpoint and suggests a meetup location for each recommended pair.

    Args:
        user_id (int): The ID of the user for whom to find recommendations.
        num_recommendations (int): Desired number of recommendations.
        initial_threshold (float): Starting similarity threshold.
        min_threshold (float): Minimum similarity threshold to try.
        step (float): Step to decrease threshold if not enough recommendations are found.
        max_geo_distance_km (float): Maximum allowed geographical distance in kilometers
                                     between users for a recommendation to be valid.

    Returns:
        list: A list of dictionaries, each containing:
              'name': recommended_friend_name,
              'similarity': similarity_score,
              'midpoint_lat': latitude of the midpoint,
              'midpoint_lon': longitude of the midpoint,
              'suggested_location': a human-readable name for the midpoint's location
    """
    if user_id < 0 or user_id >= len(df):
        print(f"Warning: Invalid user_id {user_id}. Returning empty recommendations.")
        return []

    user_distances = distances[user_id]
    user_indices = indices[user_id]

    user_lat, user_lon = df.loc[user_id, ['latitude', 'longitude']]

    current_threshold = initial_threshold

    # Attempt to find recommendations by gradually lowering the similarity threshold
    while current_threshold >= min_threshold:
        recs = []
        for i in range(1, len(user_indices)):  # Skip self (index 0)
            neighbor_idx = user_indices[i]
            similarity = 1 - user_distances[i]  # Convert cosine distance to similarity

            # Apply similarity threshold
            if similarity < current_threshold:
                continue  # Skip if not similar enough

            # Apply geographical distance filter
            neighbor_lat, neighbor_lon = df.loc[neighbor_idx, ['latitude', 'longitude']]
            geo_dist = haversine_distance(user_lat, user_lon, neighbor_lat, neighbor_lon)

            if geo_dist <= max_geo_distance_km:
                mid_lat, mid_lon = calculate_simple_midpoint(user_lat, user_lon, neighbor_lat, neighbor_lon)
                suggested_loc = get_location_name_from_coords(mid_lat, mid_lon)  # Get location name
                recs.append({
                    'name': df.loc[neighbor_idx, 'Name'],
                    'similarity': similarity,
                    'midpoint_lat': mid_lat,
                    'midpoint_lon': mid_lon,
                    'suggested_location': suggested_loc
                })

        # If enough recommendations are found, sort and return
        if len(recs) >= num_recommendations:
            recs.sort(key=lambda x: x['similarity'], reverse=True)
            return recs[:num_recommendations]

        current_threshold -= step  # Lower the similarity threshold and retry

    # Fallback: If not enough recommendations are found even after lowering the similarity
    # threshold, return the best available matches that still meet the geographical constraint.
    # This ensures some recommendations are always provided if possible.
    fallback_recs = []
    for i in range(1, len(user_indices)):
        neighbor_idx = user_indices[i]
        similarity = 1 - user_distances[i]

        neighbor_lat, neighbor_lon = df.loc[neighbor_idx, ['latitude', 'longitude']]
        geo_dist = haversine_distance(user_lat, user_lon, neighbor_lat, neighbor_lon)

        if geo_dist <= max_geo_distance_km:
            mid_lat, mid_lon = calculate_simple_midpoint(user_lat, user_lon, neighbor_lat, neighbor_lon)
            suggested_loc = get_location_name_from_coords(mid_lat, mid_lon)  # Get location name
            fallback_recs.append({
                'name': df.loc[neighbor_idx, 'Name'],
                'similarity': similarity,
                'midpoint_lat': mid_lat,
                'midpoint_lon': mid_lon,
                'suggested_location': suggested_loc
            })

    fallback_recs.sort(key=lambda x: x['similarity'], reverse=True)
    return fallback_recs[:num_recommendations]  # Return up to num_recommendations from filtered list


# --- 5. Evaluate all users ---
print("\n--- Evaluating all users ---")
all_similarities = []
recommendation_column = []
midpoint_lat_column = []
midpoint_lon_column = []
meetup_location_column = []  # New column for meetup location

# You can adjust max_geo_distance_km here for the overall evaluation
# For example, if you want to ensure recommendations are within the same country or region,
# set a reasonable distance. 500km is a common starting point for national/regional.
GEOGRAPHICAL_FILTER_KM = 750  # Increased default for broader regional recommendations

for user_id in range(len(df)):
    recs = get_friend_recommendations(user_id, num_recommendations=5, max_geo_distance_km=GEOGRAPHICAL_FILTER_KM)

    recommended_names = []
    midpoints_lat = []
    midpoints_lon = []
    meetup_locations = []

    if recs:
        sims = [r['similarity'] for r in recs]
        avg_sim = sum(sims) / len(sims)
        all_similarities.extend(sims)

        for r in recs:
            recommended_names.append(r['name'])
            midpoints_lat.append(r['midpoint_lat'])
            midpoints_lon.append(r['midpoint_lon'])
            meetup_locations.append(r['suggested_location'])  # Collect suggested location

        # print(f"User {df.loc[user_id, 'Name']} (ID {user_id}): Avg sim = {avg_sim:.3f} (Geo Filter: {GEOGRAPHICAL_FILTER_KM}km)")
    # else:
    # print(f"User {df.loc[user_id, 'Name']} (ID {user_id}): No strong matches within {GEOGRAPHICAL_FILTER_KM}km.")

    recommendation_column.append(", ".join(recommended_names))
    midpoint_lat_column.append(", ".join(map(str, midpoints_lat)))  # Store as comma-separated string
    midpoint_lon_column.append(", ".join(map(str, midpoints_lon)))  # Store as comma-separated string
    meetup_location_column.append(", ".join(meetup_locations))  # Store as comma-separated string

# Add columns
df['RecommendedFriends'] = recommendation_column
df['RecommendedFriendMidpointLat'] = midpoint_lat_column
df['RecommendedFriendMidpointLon'] = midpoint_lon_column
df['RecommendedFriendMeetupLocation'] = meetup_location_column  # Add new column

# --- 6. Print summary ---
print("\n--- Summary ---")
print(f"Evaluated {len(df)} users.")
print(f"Similarity threshold: > 0.85 (with adaptive lowering to > {get_friend_recommendations.__defaults__[3]})")
print(f"Geographical distance filter: <= {GEOGRAPHICAL_FILTER_KM} km")
if all_similarities:
    print(f"Overall average similarity (filtered): {np.mean(all_similarities):.3f}")
    print(f"Similarity range (filtered): {min(all_similarities):.3f} – {max(all_similarities):.3f}")
else:
    print("No similarities found above threshold and within geographical filter.")

# --- 7. Save updated dataset ---
OUTPUT_CSV = "SocialMediaUsers_with_Recommendations.csv"
df.to_csv(OUTPUT_CSV, index=False)
print(f"Saved updated DataFrame to '{OUTPUT_CSV}'")
